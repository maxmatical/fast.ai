{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_twitter_sentiment_transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxmatical/fast.ai/blob/master/full_twitter_sentiment_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMgx99NYbpIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/fastai/fastai.git\n",
        "!pip install transformers\n",
        "!pip install scikit-optimize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnCNplZFCBp4",
        "colab_type": "code",
        "outputId": "f056c7e9-f802-4986-9387-d12ba6133a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Set up environment and download course-v3\n",
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKq5YwwRCM5r",
        "colab_type": "code",
        "outputId": "c613c542-c6c0-4258-9723-23880310f008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.utils.show_install import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import AlbertForSequenceClassification, AlbertTokenizer, AlbertConfig\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "show_install()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "```text\n",
            "=== Software === \n",
            "python        : 3.6.9\n",
            "fastai        : 1.0.60.dev0\n",
            "fastprogress  : 0.1.22\n",
            "torch         : 1.3.1\n",
            "nvidia driver : 418.67\n",
            "torch cuda    : 10.1.243 / is available\n",
            "torch cudnn   : 7603 / is enabled\n",
            "\n",
            "=== Hardware === \n",
            "nvidia gpus   : 1\n",
            "torch devices : 1\n",
            "  - gpu0      : 16280MB | Tesla P100-PCIE-16GB\n",
            "\n",
            "=== Environment === \n",
            "platform      : Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\n",
            "distro        : #1 SMP Thu Aug 8 02:47:02 PDT 2019\n",
            "conda env     : Unknown\n",
            "python        : /usr/bin/python3\n",
            "sys.path      : \n",
            "/env/python\n",
            "/usr/lib/python36.zip\n",
            "/usr/lib/python3.6\n",
            "/usr/lib/python3.6/lib-dynload\n",
            "/usr/local/lib/python3.6/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/extensions\n",
            "/root/.ipython\n",
            "```\n",
            "\n",
            "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
            "\n",
            "Optional package(s) to enhance the diagnostics can be installed with:\n",
            "pip install distro\n",
            "Once installed, re-run this utility to get the additional information\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbCUnF1cgj9f",
        "colab_type": "code",
        "outputId": "e95cf37b-e04b-4e90-f034-5e0b085d9f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "\n",
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version : 1.0.60.dev0\n",
            "transformers version : 2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYky0SyQCZPU",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8bWDpNtCQNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('combined_tweets_clean.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLdscs8CCd--",
        "colab_type": "code",
        "outputId": "5adcce8a-6064-4136-b72c-0235ebf73498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "print(len(df))\n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>date</th>\n",
              "      <th>id</th>\n",
              "      <th>location</th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2011-08-30 23:54</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CPtte</td>\n",
              "      <td>Ok, I'm loving $GLD calls today, gold traders ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>bearish</td>\n",
              "      <td>2011-08-30 23:52</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MichaelVlaicu</td>\n",
              "      <td>@auptimus if gold corrects I'd buy out dated g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>2011-08-30 23:16</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>boposlav</td>\n",
              "      <td>What You Need to Know About the World's Larges...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>2011-08-30 23:08</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ITMTrading</td>\n",
              "      <td>Ever wanted to know the difference between GLD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>2011-08-30 23:06</td>\n",
              "      <td>1.090000e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>iembot_gld</td>\n",
              "      <td>#GLD Area Forecast Discussion (AFD) http://t.c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               text\n",
              "0           0  ...  Ok, I'm loving $GLD calls today, gold traders ...\n",
              "1           1  ...  @auptimus if gold corrects I'd buy out dated g...\n",
              "2           2  ...  What You Need to Know About the World's Larges...\n",
              "3           3  ...  Ever wanted to know the difference between GLD...\n",
              "4           4  ...  #GLD Area Forecast Discussion (AFD) http://t.c...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liW3zbbzCktu",
        "colab_type": "code",
        "outputId": "6cbdaa52-abab-49f8-d8a0-1806b25c6e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "df['sentiment'].value_counts().plot(kind='bar')\n",
        "\n",
        "print(df['sentiment'].unique())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neutral' 'bearish' 'unrelated' 'bullish']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEfCAYAAACtRRYAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XscVftJYDTQt",
        "colab_type": "text"
      },
      "source": [
        "Unrelated and neutral sentiments dominate the data currently (although this might not be the case in the future with the full dataset). It might be better to use a stratified sampling technique for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-GUhvxkELES",
        "colab_type": "code",
        "outputId": "b8d5281d-00f4-4c85-ad42-5fd1da22e13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "sss.get_n_splits(df['text'], df['sentiment'])\n",
        "\n",
        "print(sss)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2,\n",
            "            train_size=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THDVEb8tFFGN",
        "colab_type": "code",
        "outputId": "89545bf3-d281-4749-e0ba-6943993706b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_idx, val_idx = next(sss.split(df['text'], df['sentiment']))\n",
        "\n",
        "print(len(train_idx), len(val_idx))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14989 3748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnI14U3zKskb",
        "colab_type": "text"
      },
      "source": [
        "Verifying that the stratified split preseves the distribution of the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPqoB9P-JzhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df.iloc[train_idx, :]\n",
        "df_val = df.iloc[val_idx, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loavhYCJKdmz",
        "colab_type": "code",
        "outputId": "ff8db3e1-d23b-4f77-b3f3-c60fa7834c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "df_train['sentiment'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ff04ce7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEfCAYAAACtRRYAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlbcSmFoBt8sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaoWfiBQKQG2",
        "colab_type": "code",
        "outputId": "a570e708-2f3b-4dc3-9a41-c8cbe0db8abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "df_val['sentiment'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ff0224b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEfCAYAAACtRRYAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naEGsggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrWWL-PxKiZt",
        "colab_type": "text"
      },
      "source": [
        "Looks like the distribution of the labels in train and val are the same, so we can start modelling now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNDdmRdjhOcs",
        "colab_type": "text"
      },
      "source": [
        "# Setting up data for transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmsJcRyjhN6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr8kEitJhQik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "# seed = 42\n",
        "use_fp16 = False\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base' # 'roberta-base-openai-detector'\n",
        "\n",
        "# model_type = 'bert'\n",
        "# pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "# model_type = 'distilbert'\n",
        "# pretrained_model_name = 'distilbert-base-uncased-distilled-squad'#'distilbert-base-uncased'#'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "#model_type = 'xlnet'\n",
        "#pretrained_model_name = 'xlnet-base-cased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRwrbj_ohUHO",
        "colab_type": "code",
        "outputId": "cc13ec70-60aa-4941-b0b0-2e87aa0ae622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
        "model_class.pretrained_model_archive_map.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM3QmtXYhg1h",
        "colab_type": "text"
      },
      "source": [
        "## Setting up tokenizer + numericalizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB_Mk2iFhaIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "        return [CLS] + tokens + [SEP]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufWfsFnzhl3c",
        "colab_type": "code",
        "outputId": "9991e391-97e2-4751-a412-e527d4631d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 898823/898823 [00:00<00:00, 2725216.85B/s]\n",
            "100%|██████████| 456318/456318 [00:00<00:00, 1391748.28B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfKmo0fWhogF",
        "colab_type": "code",
        "outputId": "96e4a309-9979-4396-b53b-4f0d48b1c3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "tokenizer_class.pretrained_vocab_files_map"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'merges_file': {'distilroberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-merges.txt',\n",
              "  'roberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt',\n",
              "  'roberta-base-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt',\n",
              "  'roberta-large': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt',\n",
              "  'roberta-large-mnli': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-merges.txt',\n",
              "  'roberta-large-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt'},\n",
              " 'vocab_file': {'distilroberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-vocab.json',\n",
              "  'roberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json',\n",
              "  'roberta-base-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json',\n",
              "  'roberta-large': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json',\n",
              "  'roberta-large-mnli': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-vocab.json',\n",
              "  'roberta-large-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e42OyYUEhqav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KqWBee4hxz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQZYkF0fh8yN",
        "colab_type": "text"
      },
      "source": [
        "## Setting up databunch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lralLwd8h7XE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elHGg4NTiBWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "69a0abc0-cd67-438e-f108-cce52828107f"
      },
      "source": [
        "bs = 32\n",
        "\n",
        "data_clas = (TextList.from_df(df, cols='text', processor=transformer_processor)\n",
        "             .split_by_idxs(train_idx, val_idx)\n",
        "             .label_from_df(cols= 'sentiment')\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtFBaIN9iolm",
        "colab_type": "code",
        "outputId": "81cbc52a-2708-40bb-de82-df74f30a1040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "data_clas.show_batch()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] token : <s>\n",
            "[SEP] token : </s>\n",
            "[PAD] token : <pad>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠRT Ġ@ to pperc ool : Ġ@ day dev Ġ à¹ Ħ à¸ ¡ à¹ Ī à¹ ĥ à¸ Ĭ à¹ Ī à¸ Ħ à¸ £ à¸ ± à¸ ļ Ġ Ġ à¸ ķ à¸ ¥ à¸ ² à¸ Ķ à¸ Ĺ à¸ Ń à¸ ĩ à¹ Ģ à¸ ķ à¹ ĩ à¸ ¡ à¸ ķ à¸ ± à¸ § Ġ à¸ Ħ à¸ · à¸ Ń à¸ Ń</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ġ@ trade fx 24 Ġ# EU Ġ# F ines Ġ# C it igroup Ġ$ 1 . 2 Ġ# B illion ĠOver Ġ# FX Ċ Ċ tr ading Ġ# risk Ġ# big Ġ# bank Ġ# coll uding Ġ# fore x Ġexchange Ġtrading Ġ# str ateg ies Ġ Ġ Ġ Ġ Ġ Ġ Ċ Ċ # C iti Ġ$ sp y Ġ$ qq q Ġ$ d ia Ġ$ c Ġ$ j</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠðŁĺ ī ðŁĺ İ ðŁĳ į Ġ# CR U DE Ġ# OIL \" Re vers al ĠPoints Ġin ĠTIME \" Ġforecast Ġ# US OIL Ġ# UK OIL Ġ# FR ACT ALS Ġ# TR AD ING P AT TER NS Ġ# O OTT Ġ# DAY TR AD ING Ġ# F UT URES Ġ# US DO LL AR Ġ$ GL D Ġ$ SL V Ġ$ USD Ġ$ D XY Ġ$ TY</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠStr angle Ġ# Defense : ĠRolling Ġdown Ġcall Ġside Ġinto Ġa Ġstr addle Ġin Ġ$ X OP . Ċ More Ġon Ġ# trade Ġmanagement Ġin Ġmy Ġ# ebook s : Ċ https :// t . co / U q ee J k J 2 i P Ġ Ċ Ċ $ ES _ F Ġ$ N Q _ F Ġ$ Z B _ F Ġ$ SP X Ġ$ R UT</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ġ# US ĠSt ocks : ĠTech Ġ$ MS FT Ġ- 2 %. ĠL inger ie Ġ$ LB + 11 . 7 %. Veh icle ĠAuction Ġ$ C PR T Ġ+ 7 . 5 %. ĠASIC Ġ$ SN PS + 2 . 3 %. ĠMedical ĠE q p Ġ$ MD T + 2 . 5 %. ĠGold Ġ$ G OLD + 2 . 3 %. ĠCloud Ġs vc Ġ$ NT</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KApZcW2iiynP",
        "colab_type": "code",
        "outputId": "cde3f543-43c2-4f25-fa13-96b1125871e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# checking batch and numericalizer\n",
        "\n",
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = data_clas.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] id : 0\n",
            "[SEP] id : 2\n",
            "[PAD] id : 1\n",
            "Batch shape :  torch.Size([32, 202])\n",
            "tensor([[    0, 10541,   787,  ..., 24107,  5543,     2],\n",
            "        [    0,  2860, 27932,  ...,     1,     1,     1],\n",
            "        [    0, 17149,   975,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,   849, 20439,  ...,     1,     1,     1],\n",
            "        [    0,   849,   534,  ...,     1,     1,     1],\n",
            "        [    0,   849,   534,  ...,     1,     1,     1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ye6u9YhjAjH",
        "colab_type": "text"
      },
      "source": [
        "# RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhkWAqii4ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v7nVxGbjdG9",
        "colab_type": "code",
        "outputId": "1808232e-bbc3-4c5c-e861-4713977dc6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "n_labels = 4\n",
        "\n",
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = n_labels\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 473/473 [00:00<00:00, 299276.78B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 4,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1hSeT81jhdK",
        "colab_type": "code",
        "outputId": "c3013685-1620-4cf4-b04e-7359ab541717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 501200538/501200538 [00:11<00:00, 44511795.75B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Twth-Kqj_MA",
        "colab_type": "text"
      },
      "source": [
        "## Creating learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30kj8X6Vjl-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck8Xd9S_kGbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: \n",
        "    learn.destroy()\n",
        "except:\n",
        "    'no learner created'\n",
        "\n",
        "learn = Learner(data_clas,\n",
        "               custom_transformer_model,\n",
        "               opt_func = lambda input: AdamW(input,correct_bias=False, eps = 1e-4),\n",
        "               loss_func = FlattenedLoss(LabelSmoothingCrossEntropy, axis=-1),\n",
        "               metrics = [accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPJZb0kUkd80",
        "colab_type": "text"
      },
      "source": [
        "### Creating layer splitting for gradual unfreezing and discriminative learning rates\n",
        "\n",
        "use   \"num_hidden_layers\" in config + 2 (1 for embedding and 1 for head)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjACE6gekRxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For roberta-base\n",
        "list_layers = [learn.model.transformer.roberta.embeddings,\n",
        "              learn.model.transformer.roberta.encoder.layer[0],\n",
        "              learn.model.transformer.roberta.encoder.layer[1],\n",
        "              learn.model.transformer.roberta.encoder.layer[2],\n",
        "              learn.model.transformer.roberta.encoder.layer[3],\n",
        "              learn.model.transformer.roberta.encoder.layer[4],\n",
        "              learn.model.transformer.roberta.encoder.layer[5],\n",
        "              learn.model.transformer.roberta.encoder.layer[6],\n",
        "              learn.model.transformer.roberta.encoder.layer[7],\n",
        "              learn.model.transformer.roberta.encoder.layer[8],\n",
        "              learn.model.transformer.roberta.encoder.layer[9],\n",
        "              learn.model.transformer.roberta.encoder.layer[10],\n",
        "              learn.model.transformer.roberta.encoder.layer[11],\n",
        "              learn.model.transformer.roberta.pooler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1EMlOm6kr22",
        "colab_type": "code",
        "outputId": "06acb795-f2a1-4feb-bbbb-a1dfcb5564a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check groups\n",
        "learn.split(list_layers)\n",
        "num_groups = len(learn.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')\n",
        "# print(learn.layer_groups)\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 14 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBjFUqKQxgdh",
        "colab_type": "text"
      },
      "source": [
        "Optional: Freeze the model to train the head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK12C4yxk7vh",
        "colab_type": "code",
        "outputId": "275bc813-a5d8-43f9-e8ca-792d31ca3438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# learn.freeze();\n",
        "\n",
        "learn.unfreeze();\n",
        "learn.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTransformerModel\n",
              "======================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "======================================================================\n",
              "Embedding            [202, 768]           38,603,520 True      \n",
              "______________________________________________________________________\n",
              "Embedding            [202, 768]           394,752    True      \n",
              "______________________________________________________________________\n",
              "Embedding            [202, 768]           768        True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 202, 202]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [202, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [202, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [202, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [202, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Tanh                 [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [4]                  3,076      True      \n",
              "______________________________________________________________________\n",
              "\n",
              "Total params: 125,239,300\n",
              "Total trainable params: 125,239,300\n",
              "Total non-trainable params: 0\n",
              "Optimized with f5ff0aa7400\n",
              "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
              "Loss function : FlattenedLoss\n",
              "======================================================================\n",
              "Callbacks functions applied "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBlWmpdrlJxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.lr_find()\n",
        "# learn.recorder.plot(suggestion = True, skip_end=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6PHHECClV1H",
        "colab_type": "code",
        "outputId": "a3cc7c7b-1828-462c-f518-83e5b6d31598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.to_fp16()\n",
        "\n",
        "lr_init = 3e-5\n",
        "lr = lr_init\n",
        "\n",
        "\"\"\"Training without adjusting the momentum\"\"\"\n",
        "# learn.fit_one_cycle(10, \n",
        "#                     lr, \n",
        "#                     pct_start = 0.3,\n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\n",
        "\"\"\"Training discriminative learning rates\"\"\"\n",
        "# learn.fit_one_cycle(5, \n",
        "#                     slice(lr/10, lr), \n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\"\"\"\n",
        "Clipping momentum\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# learn.fit_one_cycle(10, \n",
        "#                     lr, \n",
        "#                     moms=(0.8,0.7),\n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Warmup cosine with restarts\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def fit_cosine_restart(learn, n_cycles, lr, mom, cycle_len, cycle_mult):\n",
        "    n = len(learn.data.train_dl)\n",
        "    phases = [(TrainingPhase(n * (cycle_len * cycle_mult**i))\n",
        "                 .schedule_hp('lr', lr, anneal=annealing_cos)) for i in range(n_cycles)]\n",
        "    sched = GeneralScheduler(learn, phases)\n",
        "    learn.callbacks.append(sched)\n",
        "    if cycle_mult != 1:\n",
        "        total_epochs = int(cycle_len * (1 - (cycle_mult)**n_cycles)/(1-cycle_mult)) \n",
        "    else: total_epochs = n_cycles * cycle_len\n",
        "\n",
        "    learn.fit(total_epochs, \n",
        "              callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "                                                 name='classifier_stage1')])\n",
        "\n",
        "fit_cosine_restart(learn, 15, lr, 0.9, 1, 2)\n",
        "\n",
        "\n",
        "learn.recorder.plot_losses()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='32767', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.05% [16/32767 27:34<940:36:25]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.809990</td>\n",
              "      <td>0.787768</td>\n",
              "      <td>0.766275</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.722121</td>\n",
              "      <td>0.729740</td>\n",
              "      <td>0.810832</td>\n",
              "      <td>01:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.604499</td>\n",
              "      <td>0.708761</td>\n",
              "      <td>0.828442</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.641084</td>\n",
              "      <td>0.704438</td>\n",
              "      <td>0.834045</td>\n",
              "      <td>01:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.558009</td>\n",
              "      <td>0.694617</td>\n",
              "      <td>0.844717</td>\n",
              "      <td>01:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.490135</td>\n",
              "      <td>0.708661</td>\n",
              "      <td>0.845251</td>\n",
              "      <td>01:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.471835</td>\n",
              "      <td>0.708605</td>\n",
              "      <td>0.846852</td>\n",
              "      <td>01:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.546573</td>\n",
              "      <td>0.721687</td>\n",
              "      <td>0.839114</td>\n",
              "      <td>01:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.500217</td>\n",
              "      <td>0.712621</td>\n",
              "      <td>0.843383</td>\n",
              "      <td>01:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.481167</td>\n",
              "      <td>0.726191</td>\n",
              "      <td>0.842849</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.448264</td>\n",
              "      <td>0.710272</td>\n",
              "      <td>0.852988</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.444269</td>\n",
              "      <td>0.712115</td>\n",
              "      <td>0.851654</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.412150</td>\n",
              "      <td>0.726217</td>\n",
              "      <td>0.850587</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.419903</td>\n",
              "      <td>0.726923</td>\n",
              "      <td>0.850587</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.404186</td>\n",
              "      <td>0.727540</td>\n",
              "      <td>0.849787</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.481084</td>\n",
              "      <td>0.763421</td>\n",
              "      <td>0.835646</td>\n",
              "      <td>01:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='468', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.7662753462791443.\n",
            "Better model found at epoch 1 with accuracy value: 0.8108324408531189.\n",
            "Better model found at epoch 2 with accuracy value: 0.828441858291626.\n",
            "Better model found at epoch 3 with accuracy value: 0.8340448141098022.\n",
            "Better model found at epoch 4 with accuracy value: 0.8447172045707703.\n",
            "Better model found at epoch 5 with accuracy value: 0.8452507853507996.\n",
            "Better model found at epoch 6 with accuracy value: 0.846851646900177.\n",
            "Better model found at epoch 10 with accuracy value: 0.8529882431030273.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-d8aff935cb36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m                                                  name='classifier_stage1')])\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mfit_cosine_restart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-d8aff935cb36>\u001b[0m in \u001b[0;36mfit_cosine_restart\u001b[0;34m(learn, n_cycles, lr, mom, cycle_len, cycle_mult)\u001b[0m\n\u001b[1;32m     45\u001b[0m     learn.fit(total_epochs, \n\u001b[1;32m     46\u001b[0m               callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n\u001b[0;32m---> 47\u001b[0;31m                                                  name='classifier_stage1')])\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mfit_cosine_restart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY-O__onPn31",
        "colab_type": "text"
      },
      "source": [
        "**Results**\n",
        "\n",
        "approx 85.3% accuracy training unfrozen model (without discriminative learning rate) for 5 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U2u6mCmlgMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: \n",
        "    learn.load('classifier_stage1')\n",
        "except:\n",
        "    print('no learner created')\n",
        "learn.unfreeze();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V_AlPPZ7TB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "04edfe1a-c50a-4d69-d1a1-15b0a7a9874e"
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion = True, skip_end=15)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
            "Min numerical gradient: 6.31E-07\n",
            "Min loss divided by 10: 1.10E-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEhS/x/XKkPOQG0pCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k13jU0KIqaIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80e983aa-d71f-43ed-9179-c027a26f8f81"
      },
      "source": [
        "lr = lr_init/10\n",
        "\n",
        "\"\"\"Training without adjusting the momentum\"\"\"\n",
        "# learn.fit_one_cycle(10, \n",
        "#                     lr,\n",
        "#                     pct_start = 0.3, \n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\n",
        "# \"\"\"Training discriminative learning rates\"\"\"\n",
        "# learn.fit_one_cycle(5, \n",
        "#                     slice(lr/10, lr), \n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\"\"\"\n",
        "Clipping momentum\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# learn.fit_one_cycle(10, \n",
        "#                     lr, \n",
        "#                     moms=(0.8,0.7),\n",
        "#                     callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "#                                                  name='classifier_stage1')])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "cosine anneal with restarts\n",
        "\"\"\"\n",
        "fit_cosine_restart(learn, 5, lr, 0.9, 1, 2)\n",
        "\n",
        "\n",
        "learn.recorder.plot_losses()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='17' class='' max='31', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      54.84% [17/31 28:49<23:44]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.428923</td>\n",
              "      <td>0.713174</td>\n",
              "      <td>0.855656</td>\n",
              "      <td>01:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.422075</td>\n",
              "      <td>0.718481</td>\n",
              "      <td>0.852455</td>\n",
              "      <td>01:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.419276</td>\n",
              "      <td>0.721175</td>\n",
              "      <td>0.854056</td>\n",
              "      <td>01:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.415460</td>\n",
              "      <td>0.726254</td>\n",
              "      <td>0.850587</td>\n",
              "      <td>01:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.416595</td>\n",
              "      <td>0.725289</td>\n",
              "      <td>0.851654</td>\n",
              "      <td>01:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.414781</td>\n",
              "      <td>0.725130</td>\n",
              "      <td>0.850053</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.408659</td>\n",
              "      <td>0.725505</td>\n",
              "      <td>0.849787</td>\n",
              "      <td>01:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.412875</td>\n",
              "      <td>0.731039</td>\n",
              "      <td>0.847118</td>\n",
              "      <td>01:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.415419</td>\n",
              "      <td>0.726803</td>\n",
              "      <td>0.852188</td>\n",
              "      <td>01:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.416405</td>\n",
              "      <td>0.725559</td>\n",
              "      <td>0.849253</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.420019</td>\n",
              "      <td>0.726819</td>\n",
              "      <td>0.850587</td>\n",
              "      <td>01:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.403798</td>\n",
              "      <td>0.729234</td>\n",
              "      <td>0.850053</td>\n",
              "      <td>01:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.402210</td>\n",
              "      <td>0.729883</td>\n",
              "      <td>0.851921</td>\n",
              "      <td>01:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.410119</td>\n",
              "      <td>0.730014</td>\n",
              "      <td>0.853255</td>\n",
              "      <td>01:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.406493</td>\n",
              "      <td>0.729799</td>\n",
              "      <td>0.852988</td>\n",
              "      <td>01:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.408668</td>\n",
              "      <td>0.729950</td>\n",
              "      <td>0.851921</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.405830</td>\n",
              "      <td>0.734559</td>\n",
              "      <td>0.850320</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='468', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.8556563258171082.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6b016539413a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcosine\u001b[0m \u001b[0manneal\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mrestarts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \"\"\"\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mfit_cosine_restart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-d8aff935cb36>\u001b[0m in \u001b[0;36mfit_cosine_restart\u001b[0;34m(learn, n_cycles, lr, mom, cycle_len, cycle_mult)\u001b[0m\n\u001b[1;32m     45\u001b[0m     learn.fit(total_epochs, \n\u001b[1;32m     46\u001b[0m               callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n\u001b[0;32m---> 47\u001b[0;31m                                                  name='classifier_stage1')])\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mfit_cosine_restart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er5hmarEXYuO",
        "colab_type": "text"
      },
      "source": [
        "### Getting validation accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lfy1g8yaopm",
        "colab_type": "text"
      },
      "source": [
        "1st way: using learn.get_preds() and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz0Vqm9LXaMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds, y, losses = learn.get_preds(ds_type=DatasetType.Valid, with_loss = True)\n",
        "print(accuracy(preds, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f2J2JQParAP",
        "colab_type": "text"
      },
      "source": [
        "2nd way: using learn.validate()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDgEUraUqvhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_accuracy = learn.validate(learn.data.valid_dl)[1].numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c22cWi50aJfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(val_accuracy)\n",
        "type(val_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRFf_DPKbGTs",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparam tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq1NzEGsZYQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from hyperband import hyperband\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "space = [\n",
        "         Real(0.05, 0.9, name = 'pct_start'),\n",
        "         Real(0.8, 0.9, name = 'b1'),\n",
        "         Real(0.7, 0.999, name = 'b2')\n",
        "]\n",
        "\n",
        "# add hyperparams from space here\n",
        "def fit_and_score(resources, checkpoint, pct_start, b1, b2):\n",
        "    import warnings\n",
        "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "    learn = Learner(data_clas,\n",
        "            custom_transformer_model,\n",
        "            opt_func = lambda input: AdamW(input,correct_bias=False),\n",
        "            loss_func = FlattenedLoss(LabelSmoothingCrossEntropy, axis=-1),\n",
        "            metrics = [accuracy])\n",
        "    \n",
        "    learn.to_fp16()\n",
        "\n",
        "    lr = 3e-5\n",
        "    learn.fit_one_cycle(1, \n",
        "                lr,\n",
        "                pct_start = pct_start,\n",
        "                moms = (b1, b2),\n",
        "                callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
        "                                                name='classifier_stage1')])\n",
        "\n",
        "    val_accuracy = learn.validate(learn.data.valid_dl)[1].numpy()\n",
        "\n",
        "    # Maximisation problem\n",
        "    return - val_accuracy, [pct_start, b1, b2]\n",
        "\n",
        "\n",
        "accuracies, hps = hyperband(objective=fit_and_score, dimensions=space)\n",
        "for acc, hp in zip(accuracies, hps):\n",
        "    print(acc, hp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntfPUsQEaAKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}